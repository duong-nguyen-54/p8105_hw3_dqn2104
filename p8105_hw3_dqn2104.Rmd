---
title: "homework3"
author: "Danny Nguyen"
date: "2023-10-03"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r library, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)

```


# Question 1 
```{r}
#Data Import + Data Cleaning
pols_month <- read_csv("pols-month.csv")%>%
  janitor::clean_names()%>%
  separate(mon, into = c("year", "month","day"), sep = "-")%>%
  mutate(month=month.abb[as.numeric(month)]) %>%
  mutate(president = 
           case_match(
             prez_gop,
             1 ~ "gop",
             0 ~ "dem"),
         president=as.factor(president))%>%
  select(-prez_dem, -prez_gop, -day)


snp <- read_csv("snp.csv")%>%
  janitor::clean_names()%>%
  separate(date, into = c("month", "day", "year"), sep="/")%>%
  mutate(month = as.numeric(month),
         day = as.numeric(day),
         year = as.numeric(year))%>%
  mutate(
    year = ifelse(year<23, year+2000, year+1900))%>%
  mutate (month=month.abb[month])%>%
  select(year, month, day, close)%>%
  arrange(year, month)


unemployment <- read_csv("unemployment.csv")%>%
    pivot_longer(
      Jan:Dec,
      names_to = "month",
      values_to = "unemployment")%>%
    janitor::clean_names()
```

## Merging data
```{r}
unemployment$year <- as.character (unemployment$year)
pols_month$year <- as.character (pols_month$year)
snp$year <- as.character (snp$year)
pols_snp <- left_join (pols_month, snp, by = c("year", "month"))
all <- left_join (pols_snp, unemployment, by=c("year", "month"))
```

Description: This dataset is merged from 3 individual datasets, containing 822 rows. They provide the year and month from 1947 to 2015 with information of 3 main topics: (1) Political party of the president as well as the number of senators & representatives from each side, (2) the closing values of the S&P stock index on the associated date, and (3) percentage of unemployment in each month of the associated year. Then they are merged by year& month variables leaving NAs across columns.

# Question 2 
```{r}
trash <- read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names()%>%
  select (dumpster:homes_powered)%>%
  drop_na(dumpster)%>%
  mutate(
    homes_powered = (weight_tons*500)/30)%>%
  mutate(source = "Mr.Trash Wheel")

professor_trash <- read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") %>%
  janitor::clean_names()%>%
  select (dumpster:homes_powered)%>%
  drop_na(dumpster)%>%
  mutate(
    homes_powered = (weight_tons*500)/30)%>%
  mutate( source = "Professor Trash Wheel")%>%
  mutate(sports_balls = NA) %>%
  select(1:12, sports_balls, everything())

gwynnda_trash <- read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") %>%
  janitor::clean_names()%>%
  select (dumpster:homes_powered)%>%
  drop_na(dumpster)%>%
  mutate(
    homes_powered = (weight_tons*500)/30)%>%
  mutate( source = "Gwynnda Trash Wheel") %>%
  mutate(sports_balls = NA, glass_bottles = NA)%>%
  select(1:9,glass_bottles, plastic_bags,wrappers, sports_balls, everything())

appended_trash_data <-rbind(trash, professor_trash, gwynnda_trash) 
#I made new columns that match each other so that I can append them here.

professor_trash_sum <- professor_trash %>%
  summarise(total_weight=sum(weight_tons))

gwynnda_july_cig <- gwynnda_trash %>%
  filter (month == "July" & year == "2021")%>%
  summarise(total_cig = sum(cigarette_butts))

```
Description: This appended data is comprised of 3 datasets, including Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. It contains `r nrow(appended_trash_data)` rows and `r ncol(appended_trash_data)` columns of data. Some variables being collected are numbers of different types of trash, for example plastics bottles, glass bottles, or wrappers. Among Professor Trash Wheel data, the sum of total trash weight is `r professor_trash_sum` tonnes of trash. And in Gwynnda Trash Wheel, for the month of July, there is `r gwynnda_july_cig` cigarette butts being collected. 

# Question 3 
```{r}
baseline <- read_csv("data_mci/data_mci/MCI_baseline.csv", skip = 1)%>%
  janitor::clean_names()%>%
  mutate(sex = case_match(
    sex,
    0 ~ "female", 1 ~ "male"),
    sex = as.factor(sex)) %>% 
  mutate(apoe4 = case_match(
    apoe4,
    0 ~ "non-carrier", 1 ~ "carrier"),
    apoe4 = as.factor(apoe4))
  
baseline_filtered <- baseline%>%
  filter(age_at_onset != ".")

baseline_filtered_avg_age <- baseline_filtered %>%
  summarise (average_age = mean (current_age))

women_carrier <- baseline_filtered %>%
  filter (sex== "female")%>%
  summarise (prop = mean(apoe4=="carrier"))

```
Important steps to import data are select relevant variables, filter out unnecessary observations, mutate new variables or change existing ones, and arrange in easy-to-digest format. For example, in this case, the original data has `r nrow(baseline)` recruited participants, but only `r nrow(baseline_filtered)` develop MCI in the time of this study what are qualified. Among all qualified participants, the average baseline age is `r baseline_filtered_avg_age`. Among all female participants, the proportion of women in the study are APOE4 carriers is `r women_carrier`.

## Amyloid Data
```{r}
amyloid <- read_csv("data_mci/data_mci/mci_amyloid.csv", skip = 1)%>%
  janitor::clean_names()%>%
  rename (id = "study_id")%>%
  pivot_longer( 
    baseline:time_8, 
    names_prefix = "time_",
    names_to = "years",
    values_to = "apoe4_ratio")%>%
  mutate(years = replace (years, years == "baseline", 0))%>%
  mutate(years=as.numeric(years))

```
After importing the dataset, we perform simple janitor:clean_names() and pivot_longer() to make sense of this dataset. I also renamed "study_id" into "id" for easier merging process later. 

## Check unique participants in each dataset
```{r}
anti_join(amyloid, baseline_filtered, by = "id")

anti_join(baseline_filtered, amyloid, by = "id")
```
Through the 2 lines of code above, we can see that there are unique observations that only exist in amyloid (but NOT in baseline), or just in baseline (and NOT in amyloid). Due to pivot_longer(), the number of observation may get repetitive, so we just need to keep in mind to find 'unique' data points when applicable. 

## Combine Data
```{r}
combine_MCI <- inner_join(amyloid, baseline_filtered, by="id")

length(unique(combine_MCI$id))
```
With inner_join(), this creates a dataset that has all the common participants in both datasets. However, due to the pivot_longer() amyloid data, there will be repetitive IDs. However, there are only `r length(unique(combine_MCI$id))` unique participants. 


## Export Data
```{r}
write.csv(combine_MCI, "combine_MCI.csv", row.names = FALSE)
```
